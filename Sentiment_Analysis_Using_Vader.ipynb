{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG6pnv2TJ9ZM",
        "outputId": "f03688a3-bd7d-4f53-e975-7ea484b24c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk                                # Python library for NLP\n",
        "import matplotlib.pyplot as plt            # library for visualization\n",
        "import random\n",
        "from matplotlib import style\n",
        "import seaborn as sns# pseudo-random number generator\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk import word_tokenize,sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzFgLMqaLZ_P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"himajayadav16\"\n",
        "os.environ['KAGGLE_KEY'] = \"3cd79cc7095846e734f27a1277906017\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3vCnaPBMV8q",
        "outputId": "a416e900-1e96-4b27-c342-abc4cf60e9e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from kaggle import api\n",
        "api.dataset_download_file('snap/amazon-fine-food-reviews', file_name='Reviews.csv', path='./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsWAQY2ROG3B"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the downloaded zip file\n",
        "zip_file_path = './Reviews.csv.zip'  # Update this with the actual path\n",
        "\n",
        "# Extract the CSV file from the zip archive\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "\n",
        "# Now you can read the CSV file\n",
        "csv_file_path = './Reviews.csv'  # Assuming the CSV file is named Reviews.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ4q1zaeNG7u"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('Reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1MO16MuOW7f",
        "outputId": "04f6d271-4648-44c3-fa26-cc089dd96efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2dQHmbqO6Ii",
        "outputId": "476090da-70ce-45a2-a6dc-7c8f4f3fdd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "568454\n",
            "   Id  Score                Summary  \\\n",
            "0   1      5  Good Quality Dog Food   \n",
            "1   2      1      Not as Advertised   \n",
            "2   3      4  \"Delight\" says it all   \n",
            "3   4      2         Cough Medicine   \n",
            "4   5      5            Great taffy   \n",
            "\n",
            "                                                Text  \n",
            "0  I have bought several of the Vitality canned d...  \n",
            "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  This is a confection that has been around a fe...  \n",
            "3  If you are looking for the secret ingredient i...  \n",
            "4  Great taffy at a great price.  There was a wid...  \n"
          ]
        }
      ],
      "source": [
        "cols = ['Id','Score','Summary','Text']\n",
        "df = data[cols]\n",
        "print(len(df))\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBvEZxS1gTGZ",
        "outputId": "7f4c009f-02de-4de4-cde1-d93859562ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  Score                Summary  \\\n",
            "0   1      5  Good Quality Dog Food   \n",
            "1   2      1      Not as Advertised   \n",
            "2   3      4  \"Delight\" says it all   \n",
            "3   4      2         Cough Medicine   \n",
            "4   5      5            Great taffy   \n",
            "\n",
            "                                                Text Sentiment  \n",
            "0  I have bought several of the Vitality canned d...  Positive  \n",
            "1  Product arrived labeled as Jumbo Salted Peanut...  Negative  \n",
            "2  This is a confection that has been around a fe...  Positive  \n",
            "3  If you are looking for the secret ingredient i...  Negative  \n",
            "4  Great taffy at a great price.  There was a wid...  Positive  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ec954871d81b>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Sentiment'] = pd.cut(df['Score'], bins=[0, 2, 5], labels=['Negative', 'Positive'])\n"
          ]
        }
      ],
      "source": [
        "# Assign 'Positive' sentiment to ratings 4, 4 and 5, and 'Negative' sentiment to ratings 1 and 2\n",
        "df['Sentiment'] = pd.cut(df['Score'], bins=[0, 2, 5], labels=['Negative', 'Positive'])\n",
        "\n",
        "# Print the DataFrame to see the assigned sentiment labels\n",
        "# Filter the DataFrame to show rows where the 'Score' column has a value of 3\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXDjvL-inZg-",
        "outputId": "02d713b7-e018-4698-eae6-5d8f4c9bc996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  Score                Summary  \\\n",
            "0   1      5  Good Quality Dog Food   \n",
            "1   2      1      Not as Advertised   \n",
            "2   3      4  \"Delight\" says it all   \n",
            "3   4      2         Cough Medicine   \n",
            "4   5      5            Great taffy   \n",
            "\n",
            "                                                Text Sentiment  \n",
            "0  bought sever vital can dog food product found ...  Positive  \n",
            "1  product arriv label jumbo salt peanut ... pean...  Negative  \n",
            "2  confect around centuri . light , pillowi citru...  Positive  \n",
            "3  look secret ingredi robitussin believ found . ...  Negative  \n",
            "4  great taffi great price . wide assort yummi ta...  Positive  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f13d6d5b4435>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Text'] = df.apply(tokenize_and_stem_row, axis=1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Porter Stemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# Function to tokenize and perform stemming for each row\n",
        "def tokenize_and_stem_row(row):\n",
        "    # Tokenize the text into words\n",
        "    tokens = word_tokenize(row['Text'])\n",
        "\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Perform stemming on each token\n",
        "    stemmed_tokens = [porter.stem(token) for token in filtered_tokens]\n",
        "\n",
        "\n",
        "    # Join the stemmed tokens back into a single string\n",
        "    stemmed_text = ' '.join(stemmed_tokens)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "# Tokenize and perform stemming for each row in each DataFrame\n",
        "df['Text'] = df.apply(tokenize_and_stem_row, axis=1)\n",
        "\n",
        "# Print the DataFrame to verify the transformation\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxqTTWVtjBjs",
        "outputId": "b46be56b-5e38-4ec7-ca2b-c33b3ec74796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy test: 0.8527675893430439\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def convert_to_sentiment_label(score, threshold=0):\n",
        "    if score >= threshold:\n",
        "        return 'Positive'\n",
        "    else:\n",
        "        return 'Negative'\n",
        "\n",
        "\n",
        "# 1. Combine Sentiment and Text Columns\n",
        "\n",
        "\n",
        "# 2. Split Data into Features and Target\n",
        "X = df['Text']\n",
        "y = df['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Use the sentiment analyzer to predict sentiment scores for each text in the testing data\n",
        "sentiment_scores_test = [analyzer.polarity_scores(text)['compound'] for text in X_test]\n",
        "\n",
        "# Convert sentiment scores to sentiment labels using a threshold of 0\n",
        "predicted_sentiments_test = np.array([convert_to_sentiment_label(score) for score in sentiment_scores_test])\n",
        "\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, predicted_sentiments_test)\n",
        "\n",
        "print(\"Accuracy test:\", accuracy_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}